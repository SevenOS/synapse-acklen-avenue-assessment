{
	"name": "README",
	"properties": {
		"folder": {
			"name": "documentation"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "4da39d09-0ac8-47e5-a5c0-0264bb839ae4"
			}
		},
		"metadata": {
			"saveOutput": true,
			"synapse_widget": {
				"version": "0.1"
			},
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Project: Smartbridge Data Engineer Interview Assignment\r\n",
					"\r\n",
					"> By Erick Oliveira da Silva, 17 October 2022\r\n",
					"\r\n",
					"# Introduction\r\n",
					"In this assignment, you will be working on data from a retail business, and the task is to architect/create a data platform. \r\n",
					"\r\n",
					"### Requirements:\r\n",
					"The task is to design and implement the migration strategy to migrate this table to Azure synapse from an on-prem sql server db.\r\n",
					"The solution should account for \r\n",
					"1. One time full load. \r\n",
					"2. Daily delta load. \r\n",
					"3. Ad hoc load for missed/ failed processes.\r\n",
					"\r\n",
					"With the background and data provided:\r\n",
					"1.\tWhat are the possible dimensions that could present in this data model. \r\n",
					"2.\tPlease present a draft picture of the possible data model diagram.\r\n",
					"3.\tProvide the structure of fact table in Synapse.\r\n",
					"4.\tProvide details of the table creation metrics in Synapse.\r\n",
					"5.\tPresent and explain the design and support your design choices.\r\n",
					"\r\n",
					"Suggestions:\r\n",
					"If there are any gaps in the instructions provided, please make assumptions as needed and state that clearly. \r\n",
					"\r\n",
					"## Dataset\r\n",
					"This dataset contains 27 parameters and is a slice of the transaction table, with a sample of 3000 rows. The flow of data to this table is at a rate of 200 million rows per day:\r\n",
					"\r\n",
					"`data_engineer_assignment_test_set.csv`\r\n",
					"\r\n",
					"And below is an example of what the data in a csv file, `data_engineer_assignment_test_set.csv`, looks like.\r\n",
					"\r\n",
					"![](https://saacklenavenueassessment.blob.core.windows.net/synapse-container/images/dataset-demo.png?sp=r&st=2022-10-17T22:41:29Z&se=2024-01-01T06:41:29Z&sv=2021-06-08&sr=b&sig=PzZRt0m%2FkRoesOO820IYMZZHsICAtjWdXNxP7VZ1jak%3D)\r\n",
					"\r\n",
					"## Architecture\r\n",
					"\r\n",
					"![](https://saacklenavenueassessment.blob.core.windows.net/synapse-container/images/Model_Architecture-Azure%20-%20Synapse%20-%20AA.png?sp=r&st=2022-10-18T00:47:52Z&se=2024-01-01T08:47:52Z&sv=2021-06-08&sr=b&sig=nrD2uPbXUzz51ZTtrsU%2FfSD7i3SoKWbqJm2DVbEnQOA%3D)\r\n",
					"\r\n",
					"## Resources\r\n",
					"For the design and implementation of the project architecture, the following Azure resources were chosen with a focus on the project requirements:\r\n",
					"1. Storage Account: to store the data arriving from the customer's source systems.\r\n",
					"2. Key Vault: to store the client credentials.\r\n",
					"3. SQL Server: to manage the SQL Database.\r\n",
					"4. SQL Database: to implement the data layers and be used as a processing tool for data transformations.\r\n",
					"5. Synapse: to ingest data and orchestrate the data pipelines.\r\n",
					"6. Dedicated SQL pool (formerly SQL DW): to store data in relational tables with columnar storage. This format significantly reduces data storage costs and improves query performance for business areas.\r\n",
					"\r\n",
					"![](https://saacklenavenueassessment.blob.core.windows.net/synapse-container/images/resources.png?sp=r&st=2022-10-17T22:46:23Z&se=2024-01-01T06:46:23Z&sv=2021-06-08&sr=b&sig=7hBVCg%2BIs5bSNV3aEW8HGYhwsl9QtYgjBJP2hnX4t0A%3D)\r\n",
					"\r\n",
					"## Data Layers\r\n",
					"For the implementation of the project I used the concept of Data Lakehouse to create the data layers:\r\n",
					"\r\n",
					"1. Landing: in this layer we are responsible for loading the raw data, bringing only the difference between the source vs. destination systems.\r\n",
					"2. Bronze: In this layer we will have the raw data being ingested in their respective entities in order to store all the data already loaded.\r\n",
					"3. Silver: In this layer we will start modeling the data, keeping it in third normal form as a good cleaning and normalization practice.\r\n",
					"4. Gold: In this layer we will finish the modeling, performing the denormalization of the data in order to create the facts and dimensions for the business areas to consume.\r\n",
					"\r\n",
					"## Database Schema for Silver layer\r\n",
					"### Concept: \r\n",
					"Third normal form (3NF) is a database schema design approach for relational databases which uses normalizing principles to reduce the duplication of data.\r\n",
					"\r\n",
					"![](https://saacklenavenueassessment.blob.core.windows.net/synapse-container/images/silver-schema.png?sp=r&st=2022-10-17T23:05:30Z&se=2024-01-01T07:05:30Z&sv=2021-06-08&sr=b&sig=IjkgXzShfL0PQeC1NuJUWvf6P0qTdB9jLmuBV82TgQg%3D)\r\n",
					"\r\n",
					"# What are the possible dimensions that could present in this data model\r\n",
					"1. dim_date\r\n",
					"2. dim_organization\r\n",
					"3. dim_profit_center\r\n",
					"4. dim_store\r\n",
					"\r\n",
					"# Please present a draft picture of the possible data model diagram \r\n",
					"Database Schema for Gold layer\r\n",
					"\r\n",
					"### Concept: \r\n",
					"In computing, the star schema is the simplest style of data mart schema and is the approach most widely used to develop data warehouses and dimensional data marts. The star schema consists of one or more fact tables referencing any number of dimension tables. The star schema is an important special case of the snowflake schema, and is more effective for handling simpler queries.\r\n",
					"The star schema gets its name from the physical model's resemblance to a star shape with a fact table at its center and the dimension tables surrounding it representing the star's points.\r\n",
					"\r\n",
					"![](https://saacklenavenueassessment.blob.core.windows.net/synapse-container/images/gold-schema.png?sp=r&st=2022-10-17T23:08:28Z&se=2024-01-01T07:08:28Z&sv=2021-06-08&sr=b&sig=MgmILKAIM65woaigFMjuZbJ1BR89gBwoUEx%2BfZ8o2ac%3D)\r\n",
					"\r\n",
					"# Provide the structure of fact table in Synapse\r\n",
					"```\r\n",
					"CREATE TABLE [gold].[fact_transaction]\r\n",
					"( \r\n",
					"\t[transaction_sk] [varchar](80) NOT NULL,\r\n",
					"\t[transaction_partition_key] bigint  NULL,\r\n",
					"\t[transaction_date_sk] bigint  NULL,\r\n",
					"\t[business_date_sk] bigint  NULL,\r\n",
					"\t[profit_center_sk] bigint  NULL,\r\n",
					"\t[store_sk] [varchar](10)  NULL,\r\n",
					"\t[profit_center_sk_orig] bigint  NULL,\r\n",
					"\t[organization_sk] [varchar](14)  NULL,\r\n",
					"\t[qty_transactions] [int]  NULL,\r\n",
					"\t[charges] [float]  NULL,\r\n",
					"\t[avg_charges] [float]  NULL,\r\n",
					"\t[debit] [float]  NULL,\r\n",
					"\t[discounts] [float]  NULL,\r\n",
					"\t[taxes] [float]  NULL,\r\n",
					"\t[remittance] [float]  NULL,\r\n",
					"\t[guest_count] [int]  NULL,\r\n",
					"\t[refundamt] [float]  NULL,\r\n",
					"\t[misc_charges] [float]  NULL,\r\n",
					"\t[profit] [float]  NULL\r\n",
					")\r\n",
					"WITH\r\n",
					"(\r\n",
					"\tCLUSTERED COLUMNSTORE INDEX,\r\n",
					"    DISTRIBUTION = HASH([transaction_partition_key]),\r\n",
					"    PARTITION   (   [transaction_partition_key] RANGE RIGHT FOR VALUES (202208,202209,202210,202211,202212) )\r\n",
					")\r\n",
					"```\r\n",
					"\r\n",
					"# Provide details of the table creation metrics in Synapse\r\n",
					"1. qty_transactions: sum(cast(sss_count as float))\r\n",
					"2. charges: sum(cast(charges as float))\r\n",
					"3. avg_charges: round(nullif(sum(cast(charges as float)), 0) / nullif(sum(cast(sss_count as float)), 0), 2)\r\n",
					"4. debit: sum(cast(debit as float))\r\n",
					"5. discounts: sum(cast(discounts as float))\r\n",
					"6. taxes: sum(cast(taxes as float))\r\n",
					"7. remittance: sum(cast(remittance as float))\r\n",
					"8. guest_count: sum(cast(guest_count as float))\r\n",
					"9. refundamt: sum(cast(refundamt as float))\r\n",
					"10. misc_charges: sum(cast(misc_charges as float))\r\n",
					"11. profit: sum(cast(charges as float)) - sum(cast(taxes as float))\r\n",
					"\r\n",
					"# Present and explain the design and support your design choices\r\n",
					"I made this architecture choice because it not only represents the use of the requested tools, but also meets the needs of the Data Lakehouse concept and the way I can demonstrate a fully metadata-oriented orchestration from start to finish through an azure store table .\r\n",
					"\r\n",
					"But with small adjustments I could use synapse's apache spark pools to do all the data processing (instead of Azure SQL DB) and the Storage Account to store the data with the Delta Lake framework.\r\n",
					"\r\n",
					"And it could also use Databricks instead of Synapse in order to enable other functionalities and lower the cost of spending in the cloud.\r\n",
					"\r\n",
					"## ETL Pipeline\r\n",
					"\r\n",
					"### Metadata\r\n",
					"I created an azure storage table for us to store all project metadata to use dynamically as hyperparameters through data pipelines:\r\n",
					"\r\n",
					"![](https://saacklenavenueassessment.blob.core.windows.net/synapse-container/images/storage-table.png?sp=r&st=2022-10-17T23:57:00Z&se=2024-01-01T07:57:00Z&sv=2021-06-08&sr=b&sig=Wsa8043S11n2pDjcg806AVQfVdS1r4cgLcJGEfBEpj4%3D)\r\n",
					"\r\n",
					"#### Parameters:\r\n",
					"1. PartitionKey: the json file id inside the azure store table\r\n",
					"2. RowKey: the json file row\r\n",
					"3. zone: the data layer\r\n",
					"4. table: the table name\r\n",
					"5. jobEnable: 1 referencing to enable and 0 to disable\r\n",
					"6. jobStatus: 1 referencing to success and 0 to fail\r\n",
					"7. query: the query (sql) script\r\n",
					"8. filter: the query (sql) filter (where)\r\n",
					"9. primaryKey: the table primary key\r\n",
					"10. database: the source system database\r\n",
					"11. schema: the source system schema\r\n",
					"12. fileName: the file name if we gonna ingest inside the storage account\r\n",
					"13. storageAccount: the storage account\r\n",
					"14. container: the container inside the storage account\r\n",
					"15. Timestamp: the date when the data as inserted\r\n",
					"16. fullLoad: the parameter to do a full load \r\n",
					"\r\n",
					"### Pipelines\r\n",
					"All pipelines have a very similar structure between the layers, what makes them different is that in the pipeline from landing to bronze, it is where we control whether the data coming from the source will be loaded through a full load or daily delta load.\r\n",
					"\r\n",
					"All pipelines work with incremental loads, regardless of the data layer.\r\n",
					"\r\n",
					"![](https://saacklenavenueassessment.blob.core.windows.net/synapse-container/images/pipelines.png?sp=r&st=2022-10-18T00:14:23Z&se=2024-01-01T08:14:23Z&sv=2021-06-08&sr=b&sig=G8v4c0EryJCauOEFQ5IsBs3QtY85ShW7rfyxFXPm5Hs%3D)\r\n",
					"\r\n",
					"#### Source Config.\r\n",
					"\r\n",
					"![](https://saacklenavenueassessment.blob.core.windows.net/synapse-container/images/source.png?sp=r&st=2022-10-18T00:21:47Z&se=2024-01-01T08:21:47Z&sv=2021-06-08&sr=b&sig=DUEpsOxODIb7tVQbG3kRJAG0B8EbJ2DldIQ8THBsWdo%3D)\r\n",
					"\r\n",
					"#### Sink Config.\r\n",
					"\r\n",
					"![](https://saacklenavenueassessment.blob.core.windows.net/synapse-container/images/sink.png?sp=r&st=2022-10-18T00:22:12Z&se=2024-01-01T08:22:12Z&sv=2021-06-08&sr=b&sig=FMiuHLoXbKLXMFWPTSpl8EbmUtuTfCJ89ix4RknDm8E%3D)\r\n",
					"\r\n",
					"#### Extra Configs.\r\n",
					"\r\n",
					"![](https://saacklenavenueassessment.blob.core.windows.net/synapse-container/images/log.png?sp=r&st=2022-10-18T00:22:33Z&se=2024-01-01T08:22:33Z&sv=2021-06-08&sr=b&sig=HkxJyHbUP1%2FG2ekwGn91Bj2VkJUgC3MtRZcpVKRB3%2Fc%3D)\r\n",
					"\r\n",
					"#### pl-landing-to-bronze (with the requirements)\r\n",
					"\r\n",
					"1. One time full load. \r\n",
					"2. Daily delta load. \r\n",
					"3. Ad hoc load for missed/ failed processes.\r\n",
					"\r\n",
					"![](https://saacklenavenueassessment.blob.core.windows.net/synapse-container/images/Loads.png?sp=r&st=2022-10-18T00:34:28Z&se=2024-01-01T08:34:28Z&sv=2021-06-08&sr=b&sig=DKOGRpIbgwUJ7MfMBbX0DfnqHp30hnDAgtUpXR8XCS4%3D)\r\n",
					"\r\n",
					"### Synapse Dedicated SQL pool (formerly SQL DW)\r\n",
					"\r\n",
					"![](https://saacklenavenueassessment.blob.core.windows.net/synapse-container/images/dw-tables.png?sp=r&st=2022-10-18T00:50:40Z&se=2024-01-01T08:50:40Z&sv=2021-06-08&sr=b&sig=Rv07h%2BslQbvLOPa8TMv5s3X8fT5v8%2BL7qSOQu2O4udw%3D)\r\n",
					"\r\n",
					"#### Dimensions:\r\n",
					"1. As all dimensions are smaller than 2gb, by default they were created replicated within the cluster\r\n",
					"\r\n",
					"![](https://saacklenavenueassessment.blob.core.windows.net/synapse-container/images/dim.png?sp=r&st=2022-10-18T00:56:14Z&se=2024-01-01T08:56:14Z&sv=2021-06-08&sr=b&sig=B1ygWTaxJobSWu%2BMFRWEcZykIwuPZCWSTVvlQt2De6w%3D)\r\n",
					"\r\n",
					"#### Fact:\r\n",
					"1. As the description of the data source stated, thousands of new records are loaded daily, so this will be a table that will use clustered column indexing to ensure better performance, as well as distribute your data by year and month and partition them in the same way as an example:\r\n",
					"\r\n",
					"![](https://saacklenavenueassessment.blob.core.windows.net/synapse-container/images/fact.png?sp=r&st=2022-10-18T00:56:28Z&se=2024-01-01T08:56:28Z&sv=2021-06-08&sr=b&sig=Pjxh7LIKU4xsonysu%2B%2BKehbgrRPWOU%2FjyZPMntNslmA%3D)"
				]
			}
		]
	}
}